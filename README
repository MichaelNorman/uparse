This is a universal parser generator that walks a syntax tree while parsing a
file. It has a compiler that enables you to build a syntax tree to parse any
context-free grammar that you can specify in EBNF. Conveniently, the EBNF
dialect it uses is specified in a file called ebnf_ebnf.txt in the 
../Samples/ subfolder. This file specifies the dialect of
EBNF in which it is actually written. You can use it as a guide and as a
reference example!

To build and run the project, pull it down to your machine, and open the
../UniversalParser/UniveralParser.csproj file in VS 2008. Pressing F5 results
in a stream of diagnostic messages scrolling by, indicating vagaries about
which productions are being built. When it's finished, open the Samples directory
to find a newly updated compiled_ebnf.persist file that contains a new version
of the tree used to parse EBNF. This was built from the ebnf_ebnf.txt file
mentioned earlier.

Here are the steps the code goes through to parse and build a syntax tree:
1) Program.Main() in /uparse/Program.cs is the entry point. Execution starts
   here with the slurping of ebnf_ebnf.txt into a CodeStream object. A
   CodeStream produces a notional stream of tokens from a string by wrapping
   each character in a token in which both the value and token type are the
   character itself. ("b" becomes a Token such that Token.TokenType = "b" and
   Token.Value = "b"." This allows the same loop that does the parsing to also
   do the scanning, since that loop operates on tokens.)
2) Depending on which lines you comment out, Program.cs either creates a new
   EBNF, which derives from Language, or deserializes a Language from the
   compiled_ebnf.persist file mentioned earlier.
3) No matter the case in (2), the code then calls Parse() on the EBNF or
   Parser created.
4) Parse() simply calls Compiler.Build() for each valid production it
   encounters in the file until the EOF is encountered, then calls
   Compiler.CleanUp(). CleanUp() does some tidying on the compiled tree, copying
   out GrammarNodes trees to placeholder nodes, compacting the tree, and serializing
   the Language to compiled_ebnf.persist (or whatever file you specify!).

Under the hood, a language is essentially two syntax trees, composed of GrammarNodes,
and 3 lists. The syntax trees are for the Scanner and Parser. The lists are: 
	ScannerNames, the list of names provided after the
	"export" keyword in the scanner;
	ParserNames, likewise for the parser;
	And Ignore, a list of tokens that the scanner will recognize but skip,
	when asked for the next token by the parser.
	
**The parser can only see scanner productions that are in the
scanners export list, and the compiler can only see parser productions that are in
the parser's ignore list.** Note that "see" has different meanings for the parser than
for the compiler. A parser will really only receive the tokens named in the scanner's 
export list. The compiler will receive checked TokenLists tagged with a name from the
list ParserNames so that it can build the TokenList into a semantic unit.

Don't forget to play with the simple DiagnosticCompiler to write your tokens out
to a file. Wholesome fun!

The impetus behind this project is that I had the realization that if you
tokenize the source code, the very same engine that does the scanning 
(tokenizing) can do the parsing (grammar checking), combined with the 
realization that a parser generator shouldn't generate code, but rather syntax
trees. I'm sure this isn't original, since parsing is a very mature field within
computer science, but it was a fun realization and a fairly challenging project
with which to keep my C# skills in focus!

ISSUES:
--No error messages. Good luck figuring out why your parser blew up. Adding 
error messages with line number and parser/scanner origin info is a high 
priority.

--No documentation. The example scanner, parser, and compiler exercise most of
the current functionality of the tool. If you've never parsed before, or even
if you have, it might be a bit of a trick to get it doing anything other than 
the demo functionality. In a nutshell:

--Hard-coded filenames. No UI, graphical or otherwise, for this. Simply edit the
strings in the source. It's on its way, though!

--No left-recursion checks. Again, experience needed. You need to know how to 
design a grammar that doesn't infinitely recurse. Briefly:

	expr:= (expr (+ expr)*) | /[a-z]/;

is immediately left-recursive and will loop forever. What you want is more like:

	expr:= expr_initial expr_consequent*;
	expr_item:= /[a-z]/;
	expr_initial := expr_item;
	expr_consequent := (+ expr_item);

The former encounters something that may be an expression and immediately asks,
"Is this an expression?". This causes it to ask again, "Is this an expression?"
This causes it....

The latter encounters a possible expression and asks, "Does the first part of
this look like the first part of an expression?," and then happily continues
consuming tokens until it gets an answer one way or the other.

None of that will make any sense to you in terms of GrammarNode objects if 
you've never considered manually creating a syntax tree before. Or maybe even if
you have.

--Wayyy too much fun. In spite of, or maybe because of, the issues above, it's
crazy amounts of fun to input a file and watch a useful compiled syntax tree
come out the other end, and then to use that to parse your sources!

FUTURE WORK:
--Would like to parse command-line arguments with the parser itself. Should be a
  simple trick, but will prove the technology in a "real world" example.
--Needs a GUI with a REPL. This fiddling with commenting bits out is getting old.
--I have the full EBNF for Scheme R6. I need to build this ASAP to provide
  another even more "real world" example.
--Ideas? Ping me at mknorman at that mail service provided by Google "." com.
